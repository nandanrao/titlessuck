{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_SAMPLE_SIZE = 50\n",
    "\n",
    "def sample(w, size, pwr = 1.5):\n",
    "    t,f = w[:,0], w[:,1]**pwr\n",
    "    p = f/np.linalg.norm(f, 1)\n",
    "    return np.random.choice(t, size = size, replace = True, p = p)\n",
    "\n",
    "def get_wv(model, w):\n",
    "    try:\n",
    "        return model[w]\n",
    "    except KeyError:\n",
    "        return None\n",
    "        \n",
    "def doc_vec(doc, model, corpus, size = DEFAULT_SAMPLE_SIZE, tfidf = None, count = 1):\n",
    "    \"\"\" Creates a document vector \"\"\"\n",
    "\n",
    "    tfidf = tfidf or TfidfModel(corpus)\n",
    "\n",
    "    # w is Dx2 array with word id and tfidf score\n",
    "    w = np.array(tfidf[corpus.dictionary.doc2bow(doc)])\n",
    "    \n",
    "    # sample according to tfidf scores and get vectors,\n",
    "    # filter all not-found words\n",
    "    vecs = [get_wv(model, corpus.dictionary[x]) for x in sample(w, size)]\n",
    "    vecs = [v for v in vecs if v is not None]\n",
    "\n",
    "    # Handling the cases when we find very few words from a document\n",
    "    # in our externally trained model vocabulary\n",
    "    if len(vecs) < .5*size:\n",
    "        if count < 5:\n",
    "            return doc_vec(doc, model, corpus, size, tfidf, count + 1)\n",
    "        else:\n",
    "            raise KeyError(\"Cannot find any of these words in the vocabulary: \" + \" \".join(doc))\n",
    "\n",
    "    # Just take the mean of the vec of all the sampled words from the document\n",
    "    return np.mean(vecs, 0)\n",
    "\n",
    "def corpus_vec(docs, model, corpus, size = DEFAULT_SAMPLE_SIZE):\n",
    "    \"\"\" Creates a NxD array of document vectors for each document in a list\"\"\"\n",
    "\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    N,D = len(docs), model.wv.syn0.shape[1]\n",
    "    arr = np.empty((N, D))\n",
    "    for i in range(N):\n",
    "        arr[i,:] = doc_vec(docs[i], model, corpus, size, tfidf)\n",
    "    return arr\n",
    "\n",
    "def get_closest_doc(v, cv, docs):\n",
    "    \"\"\" given a vector and 2D array of corpus vectors gives best cv\"\"\"\n",
    "    v = np.array([v])\n",
    "    d = np.argsort(cdist(v, cv)[0,:])\n",
    "    i = d[0]\n",
    "    return docs[i]\n",
    "\n",
    "def sentence_to_vec(text, model, corpus, tfidf = None):\n",
    "    doc = list(utils.tokenize(text))\n",
    "    return doc_vec(doc, model, corpus, tfidf = tfidf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import TextCorpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "corpus = TextCorpus('./jobspicker/jobspicker-descriptions.csv')\n",
    "corpus.dictionary.filter_extremes(no_below=4, no_above=.9, keep_n=100000)\n",
    "sentences = [list(g) for g in list(corpus.get_texts())]\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "model = Word2Vec.load(\"profiles.model\")\n",
    "\n",
    "corp_vecs = corpus_vec(sentences, model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'mba or master s degree is a plus benefitswe have a comprehensive benefits package here are some of the fun and meaningful perks we offer daily catered lunch monday breakfast and juice bar snacks and friday happy hours free onsite gym and fitness reimbursement seasonal sports clubs basketball hockey soccer volleyball softball and more company sponsored events transit reimbursement paid parking and shuttle service tuition assistance annual amazon discount meaningful community involvement opportunities including mentoring interns literacy tutoring and audible scholars along with collaboration on start up projects incubating in newark venture partnersaudible inc is the world s largest seller and producer of spoken audio entertainment information and educational programming since inventing and commercializing the first portable digital audio player in our focus on technological innovation and superior programming has earned us millions of subscribers around the world we re an amazon subsidiary with a presence on four different continents yet we maintain a startup vibe and small company feel we offer more than downloadable audiobooks audio editions of periodicals and other programs and an escalating array of listening products that enrich daily life for a growing population of people who want to be more productive well informed and thoughtfully entertained audible is an equal opportunity employer minority female disability vet new york area nynewark new jerseynew jersey united states audible financial systems product manager amazon com t us d a ead f bf c a ac t z https www amazon jobs en gb jobs'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = sentence_to_vec(\"outdoor independent working alone and self-motivated to work without supervision\", model, corpus, tfidf)\n",
    "a = get_closest_doc(vec, corp_vecs, sentences)\n",
    "\" \".join(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "Word2Vec.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
