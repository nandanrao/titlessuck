{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import TextCorpus, MmCorpus\n",
    "from gensim import utils\n",
    "\n",
    "# override corpus with your own tokenizer for trial/error\n",
    "list(utils.tokenize(\"energetic outdoors wilderness independence alone\"))\n",
    "\n",
    "corpus = TextCorpus('./descriptions')\n",
    "corpus.dictionary.filter_extremes(no_below=4, no_above=.9, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(408, 0.8354795905157336), (3591, 0.5495214771341174)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the BOW (TF) for a doc\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus)\n",
    "tf = corpus.dictionary.doc2bow(utils.tokenize(\"energetic outdoors wilderness independence alone\"))\n",
    "tfidf[tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model = Word2Vec.load(\"profiles.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_SAMPLE_SIZE = 10\n",
    "\n",
    "def sample(w, size, pwr = 1.75):\n",
    "    t,f = w[:,0], w[:,1]**pwr\n",
    "    p = f/np.linalg.norm(f, 1)\n",
    "    return np.random.choice(t, size = size, replace = True, p = p)\n",
    "\n",
    "def get_wv(model, w):\n",
    "    try:\n",
    "        return model[w]\n",
    "    except KeyError:\n",
    "        return None\n",
    "        \n",
    "def doc_vec(doc, model, corpus, size = DEFAULT_SAMPLE_SIZE, tfidf = None, count = 1):\n",
    "    \"\"\" Creates a document vector \"\"\"\n",
    "\n",
    "    tfidf = tfidf or TfidfModel(corpus)\n",
    "\n",
    "    # w is Dx2 array with word id and tfidf score\n",
    "    w = np.array(tfidf[corpus.dictionary.doc2bow(doc)])\n",
    "    \n",
    "    # sample according to tfidf scores and get vectors,\n",
    "    # filter all not-found words\n",
    "    vecs = [get_wv(model, corpus.dictionary[x]) for x in sample(w, size)]\n",
    "    vecs = [v for v in vecs if v is not None]\n",
    "\n",
    "    # Handling the cases when we find very few words from a document\n",
    "    # in our externally trained model vocabulary\n",
    "    if len(vecs) < .5*size:\n",
    "        if count < 5:\n",
    "            return doc_vec(doc, model, corpus, size, tfidf, count + 1)\n",
    "        else:\n",
    "            raise KeyError(\"Cannot find any of these words in the vocabulary: \" + \" \".join(doc))\n",
    "\n",
    "    # Just take the mean of the vec of all the sampled words from the document\n",
    "    return np.mean(vecs, 0)\n",
    "\n",
    "def corpus_vec(docs, model, corpus, size = DEFAULT_SAMPLE_SIZE):\n",
    "    \"\"\" Creates a NxD array of document vectors for each document in a list\"\"\"\n",
    "\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    N,D = len(docs), model.wv.syn0.shape[1]\n",
    "    arr = np.empty((N, D))\n",
    "    for i in range(N):\n",
    "        arr[i,:] = doc_vec(docs[i], model, corpus, size, tfidf)\n",
    "    return arr\n",
    "\n",
    "def get_closest_doc(v, cv, docs):\n",
    "    \"\"\" given a vector and 2D array of corpus vectors gives best cv\"\"\"\n",
    "\n",
    "    v = np.array([v])\n",
    "    d = np.argsort(cdist(v, cv)[0,:])\n",
    "    i = d[0]\n",
    "    return docs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sentences = [list(g) for g in list(corpus.get_texts())]\n",
    "corp_vecs = corpus_vec(sentences, model, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "doc = list(utils.tokenize(\"coordinator and manager with multitasking and organized excel microsoft office skills\"))\n",
    "vec = doc_vec(doc, model, corpus)\n",
    "a = get_closest_doc(vec, corp_vecs, sentences)\n",
    "\" \".join(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "Word2Vec.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
