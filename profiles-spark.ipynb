{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "df = spark.read.parquet(\"profiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "\n",
    "def parse(html):\n",
    "    return clean(BeautifulSoup(html, 'html.parser', from_encoding='ascii').text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'blah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = (df.select(\"positions.summary\")\n",
    "    .rdd\n",
    "    .map(lambda r: r.asDict()['summary'])\n",
    "    .flatMap(lambda x: x).filter(lambda x: True if x else False)\n",
    "    .map(parse)\n",
    "    .filter(lambda x: len(x) > 300)\n",
    "    .filter(lambda x: detect_language(x) == 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "rdd.map(lambda x: Row(description=x)).toDF().write.csv(\"outfile3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import itertools\n",
    "from gensim.models.word2vec_inner import FAST_VERSION, MAX_WORDS_IN_BATCH\n",
    "\n",
    "\n",
    "class TokenSentence(object):\n",
    "    \"\"\"\n",
    "    Simple format: one sentence = one line; words already preprocessed and separated by whitespace.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source, max_sentence_length=MAX_WORDS_IN_BATCH, limit=None, preprocess=lambda x: utils.to_unicode(x).split()):\n",
    "        \"\"\"\n",
    "        `source` can be either a list or single item which is either a string or a file object. Clip the file to the first\n",
    "        `limit` lines (or no clipped if limit is None, the default).\n",
    "        `preprocess` is a function that takes one argument, a string, and returns a list of tokens (defaults to utils.to_unicode(line).split())\n",
    "        Example::\n",
    "            sentences = LineSentence('myfile.txt')\n",
    "        Or for compressed files::\n",
    "            sentences = LineSentence('compressed_text.txt.bz2')\n",
    "            sentences = LineSentence('compressed_text.txt.gz')\n",
    "        \"\"\"\n",
    "        self.sources = source if type(source) == list else [source]\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.limit = limit\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through the lines in the source.\"\"\"\n",
    "        def process(source):\n",
    "            for line in itertools.islice(source, self.limit):\n",
    "                line = self.preprocess(line)\n",
    "                i = 0\n",
    "                while i < len(line):\n",
    "                    yield line[i : i + self.max_sentence_length]\n",
    "                    i += self.max_sentence_length\n",
    "\n",
    "        try:\n",
    "            # Assume it is a file-like object and try treating it as such\n",
    "            # Things that don't have seek will trigger an exception            \n",
    "            self.sources[0].seek(0)\n",
    "            for s in self.sources:\n",
    "                for i in process(s):\n",
    "                    yield i\n",
    "            \n",
    "        except AttributeError:\n",
    "            # If it didn't work like a file, use it as a string filename\n",
    "            for s in self.sources:\n",
    "                with utils.smart_open(s) as fin:\n",
    "                    for i in process(fin):\n",
    "                        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = [os.path.join(f[0],i) for f in os.walk('outfile3') for i in f[2] if re.match(r\"^part\", i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "tokenize = lambda x: list(utils.tokenize(x, lower=True, deacc=True, errors='ignore'))\n",
    "sentences = TokenSentence(files, preprocess = tokenize)\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=10, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"profiles.model\")\n",
    "model.wv.save_word2vec_format('profiles.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4124820"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
